import pickle
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models

# Define the path to the extracted CIFAR-10 dataset
DATASET_PATH = './cifar-10-batches-py'  # Update this path if necessary

# CIFAR-10 class names
class_names = [
    'Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',
    'Dog', 'Frog', 'Horse', 'Ship', 'Truck'
]

# Function to load a batch of data
def load_batch(file_path):
    with open(file_path, 'rb') as file:
        batch = pickle.load(file, encoding='latin1')
        data = batch['data']
        labels = batch['labels']
    return data, labels


# Load all training and test data
def load_cifar10_data(data_path):
    train_data = []
    train_labels = []

    # Load training batches (data_batch_1 to data_batch_5)
    for i in range(1, 6):
        file_path = os.path.join(data_path, f'data_batch_{i}')
        data, labels = load_batch(file_path)
        train_data.append(data)
        train_labels += labels

    # Combine all training batches
    train_data = np.concatenate(train_data)
    train_data = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to image format

    # Load test data
    test_data, test_labels = load_batch(os.path.join(data_path, 'test_batch'))
    test_data = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)

    return train_data, train_labels, test_data, test_labels


# Normalize pixel values to [0, 1]
def preprocess_data(data):
    return data / 255.0


# CNN Model Architecture
def create_cnn_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='softmax')  # 10 output units for 10 classes
    ])
    model.save('fdgfdssd.h5')
    return model


# Main program
if __name__ == '__main__':
    if not os.path.exists(DATASET_PATH):
        print(f"Dataset path '{DATASET_PATH}' not found. Ensure the dataset is extracted.")
    else:
        # Load CIFAR-10 dataset
        train_data, train_labels, test_data, test_labels = load_cifar10_data(DATASET_PATH)

        # Preprocess data
        train_data = preprocess_data(train_data)
        test_data = preprocess_data(test_data)

        # Display dataset information
        print(f"Train Data Shape: {train_data.shape}, Train Labels: {len(train_labels)}")
        print(f"Test Data Shape: {test_data.shape}, Test Labels: {len(test_labels)}")

        # Create and compile the CNN model
        model = create_cnn_model()
        model.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])

        # Train the model
        model.fit(train_data, np.array(train_labels), epochs=10, batch_size=64, validation_data=(test_data, np.array(test_labels)))

        # Evaluate the model
        test_loss, test_acc = model.evaluate(test_data, np.array(test_labels))
        print(f"Test Accuracy: {test_acc * 100:.2f}%")

        # Display a sample image and its predicted class
        index = 0  # You can change this index to test other samples
        plt.imshow(test_data[index])
        plt.title(f"True Label: {class_names[test_labels[index]]}")
        plt.show()

        # Make a prediction
        predictions = model.predict(test_data[index:index+1])  # Predict on one image
        predicted_class = class_names[np.argmax(predictions)]
        print(f"Predicted Label: {predicted_class}")
